{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1a51e6f",
      "metadata": {
        "id": "a1a51e6f"
      },
      "source": [
        "# Recruitment excercise\n",
        "\n",
        "Thank you for being interested in our open positions. We prepared a short exercise to assess your Machine Learning and Python coding skills. The easiest questions are at the beginning, more advanced are later on. For most of us, completing it takes more than 60 minutes, so please feel free to select the ones which are interesting for you (e.g. jump straight to the more advanced ones) and answer only those. Just please remember that data is being read only once, at the beginning and data preparation tasks are prerequisites for some tasks provided later.\n",
        "\n",
        "Also, since there's quite a lot of questions, please do not waste your time on beautifying the output or writing long answers - as long as an answer is there and it's correct, it's good enough.\n",
        "\n",
        "Important: some tasks contain questions indicated by \"‚ö†Ô∏è\" Write your answers (in English or Polish) to those questions below them in area enclosed by big red balls \"üî¥\".\n",
        "\n",
        "Also, please remember that the Internet search engines are your friends and as we're also using those in our everyday work, please feel free to use them as much as you need.\n",
        "\n",
        "The entirety of this exercise can be solved with the data provided in the same email and the following libraries:\n",
        "- pandas\n",
        "- sklearn\n",
        "- matplotlib\n",
        "- xgboost\n",
        "- optuna\n",
        "- plotly\n",
        "- tensorflow\n",
        "\n",
        "Data comes from the famours Titanic dataset, so feel free to take advantage if you played with this dataset before and it's familiar to you. Don't worry if it's new, here's the data dictionary:\n",
        "\n",
        "| Variable | Definition                                 | Key                                            |\n",
        "|----------|--------------------------------------------|------------------------------------------------|\n",
        "| survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
        "| pclass   | Ticket class (proxy for socio-economic status) | 1 = 1st (Upper), 2 = 2nd (Middle), 3 = 3rd (Lower) |\n",
        "| sex      | Sex                                        |                                                |\n",
        "| Age      | Age in years                               |                                                |\n",
        "| sibsp    | # of siblings / spouses aboard the Titanic |                                                |\n",
        "| parch    | # of parents / children aboard the Titanic |                                                |\n",
        "| ticket   | Ticket number                              |                                                |\n",
        "| fare     | Passenger fare                             |                                                |\n",
        "| cabin    | Cabin number                               |                                                |\n",
        "| embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "762859c5",
      "metadata": {
        "id": "762859c5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0873e0bf",
      "metadata": {
        "id": "0873e0bf"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1177cf",
      "metadata": {
        "id": "af1177cf"
      },
      "source": [
        "#### Task: Pandas warm-up 1/6\n",
        "\n",
        "Print unique values for the Cabin column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b33f4316",
      "metadata": {
        "scrolled": true,
        "id": "b33f4316"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "27cb857a",
      "metadata": {
        "id": "27cb857a"
      },
      "source": [
        "#### Task: Pandas warm-up 2/6\n",
        "Return the most crowded cabins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19726ac",
      "metadata": {
        "id": "b19726ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "28859161",
      "metadata": {
        "id": "28859161"
      },
      "source": [
        "#### Task: Pandas warm-up 3/6\n",
        "Using pandas methods, count number of people for each combination of Survived and Pclass levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfcf2e2e",
      "metadata": {
        "id": "cfcf2e2e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f0394b49",
      "metadata": {
        "id": "f0394b49"
      },
      "source": [
        "#### Task: Pandas warm-up 4/6\n",
        "Create a bar plot showing survival rate (%) for each combination of Sex and Pclass levels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b60c17f",
      "metadata": {
        "scrolled": true,
        "id": "3b60c17f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "392fe8cd",
      "metadata": {
        "id": "392fe8cd"
      },
      "source": [
        "#### Task: Pandas warm-up 5/6\n",
        "Create a scatter plot of Age (x-axis) and logarithmized Fare (y-axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba5209be",
      "metadata": {
        "id": "ba5209be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8cbb7739",
      "metadata": {
        "id": "8cbb7739"
      },
      "source": [
        "#### Task: Pandas warm-up 6/6\n",
        "Compute a correlation matrix for [\"Survived\", \"Pclass\", \"Age\", \"Fare\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7e5574",
      "metadata": {
        "id": "8c7e5574"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "deafb2e8",
      "metadata": {
        "id": "deafb2e8"
      },
      "source": [
        "#### Task: Data preparation 1/2\n",
        "Create a new variable \"Is_Cabin\" with 0 if \"Cabin\" was NaN and 1 otherwise. Then drop the original Cabin variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9ed5973",
      "metadata": {
        "id": "e9ed5973"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e1d34063",
      "metadata": {
        "id": "e1d34063"
      },
      "source": [
        "#### Task: Data preparation 2/2\n",
        "For the rest of NaNs, remove all rows consisting any NaNs and print the number of remaining rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133ec638",
      "metadata": {
        "id": "133ec638"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e01a87dc",
      "metadata": {
        "id": "e01a87dc"
      },
      "source": [
        "#### Task: Unsupervised learning: Clustering\n",
        "Standardize variables and run K-Means for the subset: [\"Pclass\", \"Age\", \"Fare\", \"SibSp\"]. Number of clusters doesn't matter, let's say we ask you for 4 clusters.\n",
        "\n",
        "‚ö†Ô∏èQuestion: Should one always standardize data use for K-Means clustering? Why so?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd09179",
      "metadata": {
        "id": "ccd09179"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f6588996",
      "metadata": {
        "id": "f6588996"
      },
      "source": [
        "#### Task: Unsupervised learning: Dimensionality reduction 1/2\n",
        "Create a 2-dimensional t-SNE visualization of the subset: [\"Pclass\", \"Age\", \"Fare\", \"SibSp\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "325c08ea",
      "metadata": {
        "scrolled": true,
        "id": "325c08ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ad6b8653",
      "metadata": {
        "id": "ad6b8653"
      },
      "source": [
        "#### Task: Unsupervised learning: Dimensionality reduction 2/2\n",
        "Create a 2-dimensional PCA visualization of the subset: [\"Pclass\", \"Age\", \"Fare\", \"SibSp\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69404f23",
      "metadata": {
        "id": "69404f23"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "92a933b8",
      "metadata": {
        "id": "92a933b8"
      },
      "source": [
        "#### Task: Unsupervised learning: Combining results 1/2\n",
        "Use labels provided by K-Means to enrich your t-SNE scatterplot with colors indicating assigned cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a33a8b2",
      "metadata": {
        "id": "9a33a8b2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "34e31b7a",
      "metadata": {
        "id": "34e31b7a"
      },
      "source": [
        "#### Task: Unsupervised learning: Combining results 2/2\n",
        "Use labels provided by K-Means to enrich your PCA scatterplot with colors indicating assigned cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0906c8f4",
      "metadata": {
        "id": "0906c8f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "92c474c0",
      "metadata": {
        "id": "92c474c0"
      },
      "source": [
        "#### Task: Unsupervised learning: Probing your understanding\n",
        "\n",
        "‚ö†Ô∏èQuestion: Which one would you show to your client interested in \"seeing\" the data and why?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3978e17f",
      "metadata": {
        "id": "3978e17f"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5db45d7",
      "metadata": {
        "id": "f5db45d7"
      },
      "source": [
        "#### Task: Data split\n",
        "Split your data into train (80% of data) and test (20% of data) sets with Survived being the y (dependent variable) and [\"Pclass\", \"Age\", \"Fare\", \"SibSp\", \"Is_Cabin\"] being the X (independent variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7373a813",
      "metadata": {
        "id": "7373a813"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ff08fbae",
      "metadata": {
        "id": "ff08fbae"
      },
      "source": [
        "#### Task: Supervised learning: Probing your understanding\n",
        "\n",
        "‚ö†Ô∏èQuestion: Why do we split our data into train and test (and sometimes further into validation as well)?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3b41d80",
      "metadata": {
        "id": "a3b41d80"
      },
      "source": [
        "#### Task: Decision Tree: Training\n",
        "Using your train set, train decision tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ad7f63",
      "metadata": {
        "id": "66ad7f63"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a74d7723",
      "metadata": {
        "id": "a74d7723"
      },
      "source": [
        "#### Task: Decision Tree: Performance evaluation\n",
        "Calculate and print accuracy, precision, recall, F1 and confusion matrix (protip: in sklearn, there's one method for confusion matrix and another one to all the rest) for your decision tree using test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e4aacd",
      "metadata": {
        "id": "45e4aacd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7115bc19",
      "metadata": {
        "id": "7115bc19"
      },
      "source": [
        "#### Task: Logistic Regression: Training and performance evaluation\n",
        "Using your train set, train logistic regression and check it's accuracy, precision, recall, F1 and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fb84303",
      "metadata": {
        "id": "0fb84303"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "46a6f0c9",
      "metadata": {
        "id": "46a6f0c9"
      },
      "source": [
        "#### Task: Understanding logistic regression 1/2\n",
        "\n",
        "‚ö†Ô∏èQuestion: Why statisticians (and others) care about multicollinearity when estimating linear/logistic regression models?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3cd04e0",
      "metadata": {
        "id": "b3cd04e0"
      },
      "source": [
        "#### Task: Understanding logistic regression 2/2\n",
        "\n",
        "‚ö†Ô∏èQuestion: What is p-value? How it is used in logistic regression?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942ad7fc",
      "metadata": {
        "id": "942ad7fc"
      },
      "source": [
        "#### Task: Compare models\n",
        "\n",
        "‚ö†Ô∏èQuestion: Which (decision tree vs logistic regression) model did better job (if any) and why?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "698ba4a9",
      "metadata": {
        "id": "698ba4a9"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daea0007",
      "metadata": {
        "id": "daea0007"
      },
      "source": [
        "#### Task: eXtreme Gradient Boosting and Hyperparameter Optimization\n",
        "\n",
        "An intern was asked to write a code optimizing XGB hyperparameters. They did a solid job, but... **there's a critical error in their work - can you spot and fix it?**\n",
        "\n",
        "Protip: visualizing optimization history can help you to spot it\n",
        "\n",
        "Also, please **adjust the number of trees to 2e3** - our data scientist said that the current number is not enough.\n",
        "\n",
        "‚ö†Ô∏èQuestion: Why one uses hyperparameter optimization?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f94776",
      "metadata": {
        "scrolled": true,
        "id": "92f94776"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import optuna\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def objective(trial, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test):\n",
        "    param = {\n",
        "        'tree_method':'hist',\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
        "        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008, 0.009, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]),\n",
        "        'n_estimators': 100,\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [5, 7, 9, 11, 13, 15, 17, 20]),\n",
        "        'random_state': trial.suggest_categorical('random_state', [1, 11, 131]),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
        "    }\n",
        "    model = xgb.XGBRegressor(**param)\n",
        "\n",
        "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)\n",
        "\n",
        "    predictions = [1 if x>0.5 else 0 for x in model.predict(X_test)]\n",
        "\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "\n",
        "    return f1\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fabf3d6",
      "metadata": {
        "id": "6fabf3d6"
      },
      "source": [
        "#### Task: Finding a minimum of a function the gradient way\n",
        "\n",
        "Most of Machine Learning algorithms use some sort of gradient techniques to optimize their parameters. Gradient techniques are also the very fundament of neural networks. Do you remember the basics? Please **complete the \"gradient\" function (and let it be as simple as a gradient can be) and see if it can find the global minimum of the \"our_function\" function for x_0 = 5.**\n",
        "\n",
        "Protip: before you answer the question, be smart and check (there's plenty of nice tools to plot equations on the Internet) the plot of \"our_function\" for x:<-10,10> to see how it behaves.\n",
        "\n",
        "‚ö†Ô∏èQuestion: Was it able to find the global minimum of \"our_function\" and why?‚ö†Ô∏è\n",
        "\n",
        "üî¥Answer: ...üî¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23eeff0a",
      "metadata": {
        "id": "23eeff0a"
      },
      "outputs": [],
      "source": [
        "from math import sin\n",
        "\n",
        "def gradient(func, x_0=5):\n",
        "    step = 0.001\n",
        "    alpha = 0.1\n",
        "    x_new = x_0\n",
        "    for i in range(10000):\n",
        "        x_old = x_new\n",
        "        gradient = COMPLETE_THIS_LINE\n",
        "        x_new = x_old - alpha * gradient\n",
        "    local_minimum_pretending_to_be_global_minimum = func(x_new)\n",
        "    return local_minimum_pretending_to_be_global_minimum\n",
        "\n",
        "def our_function(x):\n",
        "    return sin(8*x)+x/2+x**2\n",
        "\n",
        "print(gradient(our_function))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23f88eee",
      "metadata": {
        "id": "23f88eee"
      },
      "source": [
        "#### Task: The Very Basics of Deep Learning\n",
        "\n",
        "1. Usually, we like our final activation function to provide values ranging from 0 to 1. This code is having a different one - please fix it\n",
        "2. Please add a dropout layer\n",
        "3. Please change optimizer to adam\n",
        "4. Please provide the f1 score for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d476d11",
      "metadata": {
        "id": "2d476d11"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(optimizer='SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=0)\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Accuracy: {acc:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e06b0a",
      "metadata": {
        "id": "b1e06b0a"
      },
      "source": [
        "#### And that's it! :)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "audi",
      "language": "python",
      "name": "audi"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}